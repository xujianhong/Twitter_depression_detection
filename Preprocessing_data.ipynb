{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianhongxu/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as ddf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import time, re, os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# !pip install pysentimiento\n",
    "# from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pysentimiento\n",
    "from pysentimiento.preprocessing import preprocess_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jianhongxu/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (58.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jianhongxu/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.2.0\n",
      "    Uninstalling en-core-web-sm-2.2.0:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.0\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
    "!python3 -m spacy download en_core_web_sm  # can't find model en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partitions = 6\n",
    "\n",
    "nlp = sp.load('en_core_web_sm',disable=['parser','ner','textcat'])\n",
    "nlp.add_pipe('sentencizer') # sentence separation\n",
    "\n",
    "STOPWORDS_ENG = set(['a', 'about', 'above', 'after', 'again', 'against', 'ah', 'ai', 'ain', 'ain\"t', 'aint', 'all', 'am',\n",
    "\t\t\t\t\t\t'amp', 'an', 'and', 'any', 'are', 'aren', 'aren\"t', 'arent', 'as', 'at', 'b', 'bc', 'be', 'because',\n",
    "\t\t\t\t\t\t'been',\t'before', 'being', 'below', 'between', 'both', 'but', 'by', 'c', 'can', 'couldn', 'couldn\"t',\n",
    "\t\t\t\t\t\t'couldnt', 'd', 'did', 'didn', 'didn\"t', 'didnt', 'do', 'does', 'doesn', 'doesn\"t', 'doesnt',\n",
    "\t\t\t\t\t\t'doing', 'don', 'don\"t', 'dont', 'down',\n",
    "\t\t\t\t\t\t'during', 'e', 'each', 'f', 'few', 'for', 'from', 'ft', 'further', 'g', 'get', 'getta', 'gon',\n",
    "\t\t\t\t\t\t'gonna', 'h', 'had', 'hadn', 'hadn\"t', 'hadnt', 'has', 'hasn', 'hasn\"t', 'hasnt', 'have', 'haven',\n",
    "\t\t\t\t\t\t'haven\"t', 'havent',\n",
    "\t\t\t\t\t\t'having', 'here', 'how', 'if', 'in', 'into', 'is',\n",
    "\t\t\t\t\t\t'isn', 'isn\"t', 'isnt', 'it\"s', 'j', 'just', 'k', 'l', 'll', 'lt', 'm', 'ma',\n",
    "\t\t\t\t\t\t'mightn', 'mightn\"t', 'mightnt', 'more', 'most', 'mustn', 'mustn\"t', 'n',\n",
    "\t\t\t\t\t\t'na', 'needn', 'needn\"t', 'neednt',\n",
    "\t\t\t\t\t\t'nor', 'now', 'o', 'of', 'off', 'oh', 'on', 'once', 'only', 'or', 'other', 'out', 'over', 'own',\n",
    "\t\t\t\t\t\t'p', 'q', 'r', 're', 'rn', 'rt', 's', 'same', 'shan', 'shan\"t', 'shant', 'she\"s', 'shes',\n",
    "\t\t\t\t\t\t'should', 'should\"ve', 'shouldve', 'shouldn', 'shouldn\"t', 'shouldnt', 'so', 'some', 'such',\n",
    "\t\t\t\t\t\t't', 'ta', 'than', 'that', 'that\"ll', 'thatll',\n",
    "\t\t\t\t\t\t'the', 'then', 'there', 'these', 'this', 'those', 'through', 'to', 'too', 'under', 'until',\n",
    "\t\t\t\t\t\t'u', 'up', 'ur', 'v', 've', 'very', 'vs', 'w', 'was', 'wasn', 'wasn\"t', 'wasnt', 'were',\n",
    "\t\t\t\t\t\t'weren', 'weren\"t', 'werent', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why',\n",
    "\t\t\t\t\t\t'will', 'with', 'won', 'won\"t', 'wont', 'wouldn', 'wouldn\"t', 'wouldnt', 'x', 'y', 'yall',\n",
    "\t\t\t\t\t\t'you\"d', 'youd', 'you\"ll', 'youll', 'you\"re', 'youre', 'you\"ve', 'youve' 'z'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I student'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "def removeStopwords(text):\n",
    "  text = ' '.join([word for word in text.split() if word not in STOPWORDS_ENG])\n",
    "  return re.sub(' +',' ',text).strip()\n",
    "\n",
    "text = 'I am a student'\n",
    "print(text)\n",
    "removeStopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student.%@(())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am a student @'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "def removePunctuation(text):\n",
    "  punctuationStr= r'[_━🇧.▪\"\\[!\"#\\$%&\\(\\)\\*\\+,-\\./:;<=>\\?\\^`{\\|}~¿¡¬‘’£¥€¢₩°«»“”— ´¨¸•¤‹›–…·\\]]'\n",
    "  text = re.sub(punctuationStr,' ',text)\n",
    "  return re.sub(' +',' ',text).strip()\n",
    "\n",
    "text = 'I am a student.%@(())'\n",
    "print(text)\n",
    "removePunctuation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess tweet\n",
    "def helper_preprocess(text,demojiFlag):\n",
    "  return preprocess_tweet(text,lang='en', user_token='@usuario',\n",
    "                          url_token='url',preprocess_hashtags=True,\n",
    "                          hashtag_token=None,demoji=demojiFlag,\n",
    "                          shorten=3, normalize_laughter=True,\n",
    "                          emoji_wrapper='emoji')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('I be a student', 'I_PRON be_AUX a_DET student_NOUN')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization and POS tag\n",
    "def lemmatizeAndPOStagText(text):\n",
    "\n",
    "  doc = nlp(text)\n",
    "\n",
    "  lista_lemmatized= []\n",
    "  lista_postags_text=[]\n",
    "\n",
    "  for token in doc:\n",
    "    lista_lemmatized.append(token.lemma_)\n",
    "    lista_postags_text.append(f'{token.lemma_}_{token.pos_}')\n",
    "\n",
    "  text1 = ' '.join(lista_lemmatized).strip()\n",
    "  text2 = ' '.join(lista_postags_text).strip()\n",
    "\n",
    "  return text1, text2\n",
    "\n",
    "text = 'I am a student'\n",
    "print(text)\n",
    "lemmatizeAndPOStagText(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(allText, demojiFlag):\n",
    "  #Remove extra newlines\n",
    "  allText = [re.sub(r'[\\r|\\n|\\r\\n]+',' ',t) for t in allText]\n",
    "\n",
    "  #Remove extra whitespace\n",
    "  allText = [re.sub(' +',' ',t).strip() for t in allText]\n",
    "\n",
    "  #Replace symbols (eg. I’m --> I'm   that´s --> that's)\n",
    "  allText = [re.sub('’', '\\'', t) for t in allText]\n",
    "  allText = [re.sub('”', '\\'', t) for t in allText]\n",
    "  allText = [re.sub('´', '\\'', t) for t in allText]\n",
    "  allText = [re.sub('\"', '\\'', t) for t in allText]\n",
    "\n",
    "  allText = [re.sub('‑', '-', t) for t in allText]\n",
    "  allText = [re.sub('—', '-', t) for t in allText]\n",
    "\n",
    "  #Preprocess tweet using pysentimiento\n",
    "  allText = [helper_preprocess(t, demojiFlag) for t in allText]\n",
    "\n",
    "  allText = [removePunctuation(t) for t in allText]\n",
    "\n",
    "  # Lowercase\n",
    "  allText = [t.lower() for t in allText]\n",
    "\n",
    "  return allText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanProcessDataframe(df):\n",
    "\n",
    "  clean_tweets = processText(df['tweet'].values, demojiFlag=False)\n",
    "\n",
    "  result1 = []\n",
    "  result2 = []\n",
    "  for t in clean_tweets:\n",
    "    lst1, lst2 = lemmatizeAndPOStagText(t)\n",
    "    result1.append(lst1)\n",
    "    result2.append(lst2)\n",
    "\n",
    "  df['clean_tweet_lemma'] = result1\n",
    "  df['clean_tweet_lemma_postags'] = result2\n",
    "\n",
    "  clean_tweets_nostop = [removeStopwords(t) for t in clean_tweets]\n",
    "\n",
    "  result1 = []\n",
    "  result2 = []\n",
    "  for t in clean_tweets_nostop:\n",
    "    lst1, lst2 = lemmatizeAndPOStagText(t)\n",
    "    result1.append(lst1)\n",
    "    result2.append(lst2)\n",
    "\n",
    "  df['clean_tweet_nostop_lemma'] = result1\n",
    "  df['clean_tweet_nostop_lemma_postags'] = result2\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertNum(value):\n",
    "  return 0 if (value == np.nan) else value\n",
    "\n",
    "\n",
    "def convertText(value):\n",
    "  return '' if (value == np.nan) else value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   class                 80 non-null     object\n",
      " 1   tweet_id              80 non-null     int64 \n",
      " 2   day                   80 non-null     object\n",
      " 3   time                  80 non-null     object\n",
      " 4   tweet                 80 non-null     object\n",
      " 5   tweet_favorite_count  80 non-null     int64 \n",
      " 6   tweet_retweet_count   80 non-null     int64 \n",
      " 7   tweet_source          80 non-null     object\n",
      " 8   user_id               80 non-null     int64 \n",
      " 9   user_followers_count  80 non-null     int64 \n",
      " 10  user_friends_count    80 non-null     int64 \n",
      " 11  user_listed_count     80 non-null     int64 \n",
      " 12  user_statuses_count   80 non-null     int64 \n",
      "dtypes: int64(8), object(5)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/jianhongxu/python_project/twitter_dataset/Timelines/English/Adhd_eng/usuario_15000.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** /Users/jianhongxu/python_project/twitter_dataset/Timelines/English/Depression_eng ***\n",
      "Number of users: 249\n",
      "Processing 99/249,29-08-2024 10:43:00\n",
      "Processing 199/249,29-08-2024 10:58:45\n"
     ]
    }
   ],
   "source": [
    "def preprocessingData(fileName):\n",
    "  timelineDirectory = f'/Users/jianhongxu/python_project/twitter_dataset/Timelines/English/{fileName}'\n",
    "\n",
    "  cleanUsersDirectory = f'/Users/jianhongxu/python_project/twitter_dataset/Timelines/English/clean_users/{fileName}'\n",
    "  if not os.path.exists(cleanUsersDirectory):\n",
    "    os.makedirs(cleanUsersDirectory)\n",
    "\n",
    "  print(f'*** {timelineDirectory} ***')\n",
    "\n",
    "  usuarios = os.listdir(timelineDirectory)\n",
    "  print(f'Number of users: {len(usuarios)}')\n",
    "\n",
    "  for count, user in enumerate(usuarios):\n",
    "\n",
    "    # print(f'\\n** {user} ***\\n')\n",
    "    # print(f'{datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")}')\n",
    "\n",
    "    # print('Start...')\n",
    "\n",
    "    # start_time = time.time()\n",
    "\n",
    "    df = pd.read_csv(os.path.join(timelineDirectory,user),\n",
    "                     low_memory=True,\n",
    "                     converters={'tweet':convertText,'tweet_favorite_count':convertNum,\n",
    "                                 'tweet_retweet_count':convertNum},\n",
    "                     dtype={'tweet_id':str,'user_id':str})\n",
    "    df['clean_tweet_lemma'] = ''\n",
    "    df['clean_tweet_lemma_postags'] = ''\n",
    "\n",
    "    df['clean_tweet_nostop_lemma'] = ''\n",
    "    df['clean_tweet_nostop_lemma_postags'] = ''\n",
    "\n",
    "    dask_dataframe = ddf.from_pandas(df,npartitions=n_partitions)\n",
    "\n",
    "    # print(df.shape)\n",
    "    # print(f'df: {df.columns}')\n",
    "    # print(f'dask_dataframe: {dask_dataframe.columns}')\n",
    "    result = dask_dataframe.map_partitions(cleanProcessDataframe, meta=df)\n",
    "    df = result.compute()\n",
    "\n",
    "    cleanData = df[['class','tweet_id','day','time',\n",
    "                    'tweet',\n",
    "                    'clean_tweet_lemma','clean_tweet_lemma_postags',\n",
    "                    'clean_tweet_nostop_lemma','clean_tweet_nostop_lemma_postags',\n",
    "                    'tweet_favorite_count','tweet_retweet_count',\n",
    "                    'tweet_source',\n",
    "                    'user_id',\n",
    "                    'user_followers_count','user_friends_count',]]\n",
    "    cleanData = cleanData[cleanData['clean_tweet_lemma'] != '']\n",
    "\n",
    "    # print(cleanData.shape)\n",
    "\n",
    "    cleanData.to_csv(os.path.join(cleanUsersDirectory, f'user_{user}'), index = False)\n",
    "\n",
    "    # end_time = time.time()\n",
    "    # print(f'Time: {(end_time - start_time) / 60.0}')\n",
    "\n",
    "    if(count + 1) % 100 == 0:\n",
    "      print(f'Processing {count}/{len(usuarios)},{datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")}')\n",
    "\n",
    "\n",
    "# preprocessingData('Adhd_eng')\n",
    "#Number of users: 622\n",
    "# Processing 99/622,28-08-2024 20:26:52\n",
    "# Processing 199/622,28-08-2024 20:50:31\n",
    "# Processing 299/622,28-08-2024 21:13:32\n",
    "# Processing 399/622,28-08-2024 21:32:43\n",
    "# Processing 499/622,28-08-2024 21:48:13\n",
    "# Processing 599/622,28-08-2024 22:04:26\n",
    "\n",
    "# preprocessingData('Bipolar_eng')\n",
    "# Number of users: 136\n",
    "# 22m 43.2s\n",
    "\n",
    "# preprocessingData('Control_eng')\n",
    "# 298m 41.3s\n",
    "# Number of users: 1703\n",
    "\n",
    "preprocessingData('Depression_eng')\n",
    "# 39m 35.3s\n",
    "# Number of users: 249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 15 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   class                             80 non-null     object\n",
      " 1   tweet_id                          80 non-null     int64 \n",
      " 2   day                               80 non-null     object\n",
      " 3   time                              80 non-null     object\n",
      " 4   tweet                             80 non-null     object\n",
      " 5   clean_tweet_lemma                 80 non-null     object\n",
      " 6   clean_tweet_lemma_postags         80 non-null     object\n",
      " 7   clean_tweet_nostop_lemma          80 non-null     object\n",
      " 8   clean_tweet_nostop_lemma_postags  80 non-null     object\n",
      " 9   tweet_favorite_count              80 non-null     int64 \n",
      " 10  tweet_retweet_count               80 non-null     int64 \n",
      " 11  tweet_source                      80 non-null     object\n",
      " 12  user_id                           80 non-null     int64 \n",
      " 13  user_followers_count              80 non-null     int64 \n",
      " 14  user_friends_count                80 non-null     int64 \n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/jianhongxu/python_project/twitter_dataset/Timelines/English/clean_users/Adhd_eng/user_usuario_15000.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"@USER AAABDVSGJS NOO you're too kind 😭🥺 more like i plagued everyone 😤 me too aaa gdjshvdh im super happy i met you and enjoyed myself in this space 🥺🥰💞💕\"\n",
      "' @usuario aaabdvsgjs noo you be too kind 😭 🥺 more like I plague everyone 😤 I too aaa gdjshvdh I m super happy I meet you and enjoy myself in this space 🥺 🥰 💞 💕 '\n",
      "'_PUNCT @usuario_ADV aaabdvsgjs_PROPN noo_PROPN you_PRON be_AUX too_ADV kind_ADV 😭_ADJ 🥺_PROPN more_ADV like_ADP I_PRON plague_VERB everyone_PRON 😤_PUNCT I_PRON too_ADV aaa_PROPN gdjshvdh_PROPN I_PRON m_VERB super_ADV happy_ADJ I_PRON meet_VERB you_PRON and_CCONJ enjoy_VERB myself_PRON in_ADP this_DET space_NOUN 🥺_PROPN 🥰_PROPN 💞_NOUN 💕_X '_PUNCT\n",
      "' @usuario aaabdvsgjs noo you be kind 😭 🥺 like I plague everyone 😤 I aaa gdjshvdh I m super happy I meet you enjoy myself space 🥺 🥰 💞 💕 '\n",
      "'_PUNCT @usuario_ADV aaabdvsgjs_PROPN noo_PROPN you_PRON be_AUX kind_ADV 😭_ADJ 🥺_ADJ like_ADP I_PRON plague_VERB everyone_PRON 😤_PROPN I_PRON aaa_NOUN gdjshvdh_PROPN I_PRON m_VERB super_ADV happy_ADJ I_PRON meet_VERB you_PRON enjoy_VERB myself_PRON space_PROPN 🥺_PROPN 🥰_PROPN 💞_NOUN 💕_X '_PUNCT\n"
     ]
    }
   ],
   "source": [
    "tweet = df['tweet'][0]\n",
    "clean_tweet_lemma = df['clean_tweet_lemma'][0]\n",
    "clean_tweet_lemma_postags = df['clean_tweet_lemma_postags'][0]\n",
    "clean_tweet_nostop_lemma = df['clean_tweet_nostop_lemma'][0]\n",
    "clean_tweet_nostop_lemma_postags = df['clean_tweet_nostop_lemma_postags'][0]\n",
    "print(tweet)\n",
    "print(clean_tweet_lemma)\n",
    "print(clean_tweet_lemma_postags)\n",
    "print(clean_tweet_nostop_lemma)\n",
    "print(clean_tweet_nostop_lemma_postags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
